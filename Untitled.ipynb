{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating encoder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                100368    \n",
      "=================================================================\n",
      "Total params: 193,936\n",
      "Trainable params: 193,488\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latentDim = 16\n",
    "encoderInput = Input(shape=(28, 28, 1)) \n",
    "\n",
    "X = Conv2D(32, (3, 3), strides=2, padding=\"same\", activation=\"relu\")(encoderInput)\n",
    "X = BatchNormalization(axis=-1)(X)\n",
    "X = Conv2D(64, (3, 3), strides=2, padding=\"same\", activation=\"relu\")(X)\n",
    "X = BatchNormalization(axis=-1)(X)\n",
    "X = Conv2D(128, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(X)\n",
    "X = BatchNormalization(axis=-1)(X)\n",
    "volumeSize = K.int_shape(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(latentDim)(X)\n",
    "\n",
    "encoder = Model(encoderInput, X, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating decoder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6272)              106624    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 347,649\n",
      "Trainable params: 347,201\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoderInput = Input(shape=(latentDim,))\n",
    "X = Dense(np.prod(volumeSize[1:]))(decoderInput)\n",
    "X = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(X)\n",
    "X = Conv2DTranspose(128, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(X)\n",
    "X = BatchNormalization(axis=-1)(X)\n",
    "X = Conv2DTranspose(64, (3, 3), strides=2, padding=\"same\", activation=\"relu\")(X)\n",
    "X = BatchNormalization(axis=-1)(X)\n",
    "X = Conv2DTranspose(32, (3, 3), strides=2, padding=\"same\", activation=\"relu\")(X)\n",
    "X = BatchNormalization(axis=-1)(X)\n",
    "X = Conv2DTranspose(1, (3, 3), padding=\"same\", activation=\"sigmoid\")(X)\n",
    "\n",
    "decoder = Model(decoderInput, X, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoencoder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                193936    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         347649    \n",
      "=================================================================\n",
      "Total params: 541,585\n",
      "Trainable params: 540,689\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(encoderInput, decoder(encoder(encoderInput)), name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test  = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# We'll put the 0 number as the anomaly and 2 as valide\n",
    "anomaliesIndxs = np.where(y_train == 0)[0]\n",
    "validesIndxs = np.where(y_train == 5)[0]\n",
    "\n",
    "random.shuffle(anomaliesIndxs)\n",
    "random.shuffle(validesIndxs)\n",
    "\n",
    "anomaliesIndxs = anomaliesIndxs[:int(len(anomaliesIndxs) * 0.01)]\n",
    "\n",
    "anomalyImages = x_train[anomaliesIndxs]\n",
    "valideImages  = x_train[validesIndxs]\n",
    "#data = np.vstack([valideImages , anomalyImages])\n",
    "data = np.vstack([valideImages])\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "data = data.astype(\"float32\") / 255.0\n",
    "(trainX, testX) = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4336 samples, validate on 1085 samples\n",
      "Epoch 1/20\n",
      "4336/4336 [==============================] - 5s 1ms/step - loss: 0.0154 - val_loss: 0.0177\n",
      "Epoch 2/20\n",
      "4336/4336 [==============================] - 3s 714us/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 3/20\n",
      "4336/4336 [==============================] - 3s 753us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 4/20\n",
      "4336/4336 [==============================] - 3s 752us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 5/20\n",
      "4336/4336 [==============================] - 3s 739us/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 6/20\n",
      "4336/4336 [==============================] - 3s 770us/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 7/20\n",
      "4336/4336 [==============================] - 3s 698us/step - loss: 0.0067 - val_loss: 0.0088\n",
      "Epoch 8/20\n",
      "4336/4336 [==============================] - 3s 697us/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 9/20\n",
      "4336/4336 [==============================] - 3s 678us/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 10/20\n",
      "4336/4336 [==============================] - 3s 673us/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 11/20\n",
      "4336/4336 [==============================] - 3s 681us/step - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 12/20\n",
      "4336/4336 [==============================] - 3s 669us/step - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 13/20\n",
      "4336/4336 [==============================] - 3s 661us/step - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 14/20\n",
      "4336/4336 [==============================] - 3s 729us/step - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 15/20\n",
      "4336/4336 [==============================] - 3s 665us/step - loss: 0.0054 - val_loss: 0.0075\n",
      "Epoch 16/20\n",
      "4336/4336 [==============================] - 3s 674us/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 17/20\n",
      "4336/4336 [==============================] - 3s 666us/step - loss: 0.0051 - val_loss: 0.0071\n",
      "Epoch 18/20\n",
      "4336/4336 [==============================] - 3s 658us/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 19/20\n",
      "4336/4336 [==============================] - 3s 658us/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 20/20\n",
      "4336/4336 [==============================] - 3s 660us/step - loss: 0.0049 - val_loss: 0.0074\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "opt = Adam(lr= INIT_LR, decay = INIT_LR / EPOCHS)\n",
    "autoencoder.compile(loss=\"mse\", optimizer=opt)\n",
    "history = autoencoder.fit(trainX, trainX, \n",
    "                         validation_data=(testX, testX),\n",
    "                         epochs=20,\n",
    "                         batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005913217440842201,\n",
       " 0.005837716544123409,\n",
       " 0.0035511301791672986,\n",
       " 0.00435151679308341,\n",
       " 0.003601863824057576,\n",
       " 0.011453495986194549,\n",
       " 0.003177067667524116,\n",
       " 0.003586453402959398,\n",
       " 0.00840175040502938,\n",
       " 0.0018061038940439035,\n",
       " 0.00853401123849724,\n",
       " 0.00224714522731697,\n",
       " 0.003303433092607596,\n",
       " 0.010869670953819957,\n",
       " 0.006161247002318175,\n",
       " 0.0029811028800269205,\n",
       " 0.0027087101170423862,\n",
       " 0.004829667774443836,\n",
       " 0.006118513025497757,\n",
       " 0.007800934878577158,\n",
       " 0.005225873426833867,\n",
       " 0.005776476641977869,\n",
       " 0.004661528363505845,\n",
       " 0.007061630795847166,\n",
       " 0.007364718554124639,\n",
       " 0.006334305146796822,\n",
       " 0.0030273270051752086,\n",
       " 0.0021754114359015006,\n",
       " 0.0023375195980542334,\n",
       " 0.002993245868360731,\n",
       " 0.0027169200559462375,\n",
       " 0.0021014869548451965,\n",
       " 0.0054323141376768,\n",
       " 0.007268722978756321,\n",
       " 0.004127053688961302,\n",
       " 0.0036914999902153017,\n",
       " 0.00774260849313573,\n",
       " 0.0054458273986839265,\n",
       " 0.00585672170296023,\n",
       " 0.009804516170242944,\n",
       " 0.003721486993474776,\n",
       " 0.00948571990662294,\n",
       " 0.002408392557029201,\n",
       " 0.0040225399287381275,\n",
       " 0.0027457230828515297,\n",
       " 0.002792655754991706,\n",
       " 0.0097332087664066,\n",
       " 0.005008412419504649,\n",
       " 0.005479685278918501,\n",
       " 0.008657547707428544,\n",
       " 0.004935134405983891,\n",
       " 0.005792456628885971,\n",
       " 0.003902476337379745,\n",
       " 0.00344358073101143,\n",
       " 0.0016914443423411783,\n",
       " 0.004328810453467912,\n",
       " 0.004861939778884758,\n",
       " 0.004596196957184477,\n",
       " 0.005276718191745367,\n",
       " 0.0046024308050820134,\n",
       " 0.010765755536624183,\n",
       " 0.009089529080529147,\n",
       " 0.007274800087923101,\n",
       " 0.004826921403071982,\n",
       " 0.0023005332419074485,\n",
       " 0.005490538436908673,\n",
       " 0.0036151538880718087,\n",
       " 0.0017193812856996587,\n",
       " 0.004242848682263292,\n",
       " 0.004180401191576415,\n",
       " 0.003190105831265524,\n",
       " 0.005285644273249139,\n",
       " 0.0021416409881301127,\n",
       " 0.0035575044715763482,\n",
       " 0.004714043112479938,\n",
       " 0.007780880075060227,\n",
       " 0.003439713745685879,\n",
       " 0.0030916414653434777,\n",
       " 0.004697835204693527,\n",
       " 0.0038342772910683097,\n",
       " 0.008564015453262686,\n",
       " 0.0037983709057489495,\n",
       " 0.015204107558696923,\n",
       " 0.006445967438597119,\n",
       " 0.007866348201674577,\n",
       " 0.0038869151341944966,\n",
       " 0.0037500840446886585,\n",
       " 0.0035733611896900243,\n",
       " 0.004323417799806581,\n",
       " 0.0043611898796145285,\n",
       " 0.004170883657616888,\n",
       " 0.003542656212401611,\n",
       " 0.007093183570877044,\n",
       " 0.016161787570050497,\n",
       " 0.006398016896276384,\n",
       " 0.006578223887124797,\n",
       " 0.0035216318749455608,\n",
       " 0.0034388607414262045,\n",
       " 0.00374588004056055,\n",
       " 0.00562459641143233,\n",
       " 0.007184018768817727,\n",
       " 0.003790497790488771,\n",
       " 0.008215301268462184,\n",
       " 0.0051724667302022916,\n",
       " 0.004689994157547051,\n",
       " 0.010209720500436783,\n",
       " 0.003980877570937147,\n",
       " 0.005453104311736733,\n",
       " 0.006923187859097272,\n",
       " 0.0034797523075460707,\n",
       " 0.00267430503014911,\n",
       " 0.007984044117386898,\n",
       " 0.005079459609797863,\n",
       " 0.0052234140442521245,\n",
       " 0.0027224800749272747,\n",
       " 0.014649367603290825,\n",
       " 0.00409282392254514,\n",
       " 0.004068671061353892,\n",
       " 0.004123450329621034,\n",
       " 0.0021905471358079514,\n",
       " 0.0059988148451258355,\n",
       " 0.0016543387798864627,\n",
       " 0.0011431093912721132,\n",
       " 0.005535075862095403,\n",
       " 0.009164317892490096,\n",
       " 0.002370199253445059,\n",
       " 0.002377904193717946,\n",
       " 0.004792818399272469,\n",
       " 0.0147449554100447,\n",
       " 0.004962864474402975,\n",
       " 0.00584334256115765,\n",
       " 0.0029671734647261994,\n",
       " 0.010333379056705314,\n",
       " 0.0034881132022290835,\n",
       " 0.004030327153588247,\n",
       " 0.01321627623129198,\n",
       " 0.0038390213203550053,\n",
       " 0.00613485538832245,\n",
       " 0.007579357967709328,\n",
       " 0.005451932960738618,\n",
       " 0.004101753132542307,\n",
       " 0.006077157227360662,\n",
       " 0.003992573159016337,\n",
       " 0.005622685127658468,\n",
       " 0.0032386962720882652,\n",
       " 0.004475103657333031,\n",
       " 0.0059627325931024535,\n",
       " 0.004935490508091921,\n",
       " 0.003817816947462478,\n",
       " 0.01388057806524145,\n",
       " 0.007914538601216938,\n",
       " 0.0023447847505918278,\n",
       " 0.002946705793035269,\n",
       " 0.0029613269594595593,\n",
       " 0.005765183928789653,\n",
       " 0.015571769555567806,\n",
       " 0.003259777381271869,\n",
       " 0.006582213798434031,\n",
       " 0.004789042979137654,\n",
       " 0.005130814970809986,\n",
       " 0.0035685245828734583,\n",
       " 0.004529622516845262,\n",
       " 0.00953066183255517,\n",
       " 0.00684082842905023,\n",
       " 0.004612969907794426,\n",
       " 0.004773067058905745,\n",
       " 0.005464098388900788,\n",
       " 0.007591949616076928,\n",
       " 0.004516932082313868,\n",
       " 0.0045025807121433425,\n",
       " 0.004648560651040991,\n",
       " 0.0029678631262840985,\n",
       " 0.006748781805520856,\n",
       " 0.016438702425120775,\n",
       " 0.0030681460840730115,\n",
       " 0.0032315436846908152,\n",
       " 0.00336222615799033,\n",
       " 0.002645810101528214,\n",
       " 0.01708238822527656,\n",
       " 0.004065738815963887,\n",
       " 0.003679953408457762,\n",
       " 0.0036229375939194662,\n",
       " 0.007758640222274312,\n",
       " 0.003885311922738494,\n",
       " 0.005200166011313035,\n",
       " 0.0016183171982745454,\n",
       " 0.004515687361877284,\n",
       " 0.006470885602168027,\n",
       " 0.004899947436929559,\n",
       " 0.005781236092854681,\n",
       " 0.006894140782056065,\n",
       " 0.0017795554824488063,\n",
       " 0.0065549016511489136,\n",
       " 0.005489879701895322,\n",
       " 0.006262120352714728,\n",
       " 0.005408854809403597,\n",
       " 0.004068964251253395,\n",
       " 0.0026607843508364556,\n",
       " 0.004291353834619283,\n",
       " 0.009061564440249527,\n",
       " 0.004143666296136797,\n",
       " 0.007678888625049661,\n",
       " 0.0019093377346565744,\n",
       " 0.004586599555665487,\n",
       " 0.013230491455915202,\n",
       " 0.008826969440960291,\n",
       " 0.011548299729171365,\n",
       " 0.0029667370161669876,\n",
       " 0.004925067560188957,\n",
       " 0.003922700762709688,\n",
       " 0.0041738124662205655,\n",
       " 0.004399550664495384,\n",
       " 0.004384408909031708,\n",
       " 0.0040827190006316695,\n",
       " 0.004758573890812961,\n",
       " 0.015072425809370528,\n",
       " 0.005746928472904477,\n",
       " 0.005377416501667776,\n",
       " 0.007496166486604307,\n",
       " 0.0023099297443393255,\n",
       " 0.004395047304849581,\n",
       " 0.004529108299042268,\n",
       " 0.00529089379206292,\n",
       " 0.0037684496525526665,\n",
       " 0.0039860489098512515,\n",
       " 0.004442217204906435,\n",
       " 0.005666757977466634,\n",
       " 0.009591765063302815,\n",
       " 0.0067979055858912105,\n",
       " 0.00499976992804445,\n",
       " 0.0031794589147509113,\n",
       " 0.0027798846567123037,\n",
       " 0.004438170447853034,\n",
       " 0.0029227153571163293,\n",
       " 0.004025177627138864,\n",
       " 0.0044796606507699005,\n",
       " 0.005872052584906624,\n",
       " 0.011630163920670962,\n",
       " 0.005366563977542112,\n",
       " 0.004281384199594444,\n",
       " 0.003290838895743684,\n",
       " 0.005461427069386755,\n",
       " 0.005805616510239251,\n",
       " 0.004458063745258063,\n",
       " 0.025687805713693196,\n",
       " 0.004473809153859929,\n",
       " 0.009597111807447786,\n",
       " 0.005813807438716539,\n",
       " 0.005619893844450879,\n",
       " 0.0028852822431013987,\n",
       " 0.0023214896019489698,\n",
       " 0.00378158572201893,\n",
       " 0.004762024964581225,\n",
       " 0.00854424739880948,\n",
       " 0.002460785741603945,\n",
       " 0.004007930495312564,\n",
       " 0.005369450172529012,\n",
       " 0.0053525741238611676,\n",
       " 0.004137754270062679,\n",
       " 0.003671420976909207,\n",
       " 0.0037435907707236505,\n",
       " 0.007702231180615986,\n",
       " 0.00634970451337623,\n",
       " 0.010072795218474283,\n",
       " 0.006170981382940218,\n",
       " 0.007506895001856014,\n",
       " 0.003415215600937719,\n",
       " 0.002883480003209373,\n",
       " 0.003558402256209989,\n",
       " 0.006742848256603059,\n",
       " 0.008446616301847175,\n",
       " 0.005766216590696367,\n",
       " 0.006569272988666948,\n",
       " 0.006377742669750559,\n",
       " 0.007532018292685469,\n",
       " 0.008992757411222265,\n",
       " 0.006992672152450808,\n",
       " 0.0031084909002719804,\n",
       " 0.0024742942411063243,\n",
       " 0.0035451097870867056,\n",
       " 0.009870321086474943,\n",
       " 0.0035292677570730917,\n",
       " 0.003615535225914592,\n",
       " 0.0031598786933663783,\n",
       " 0.0024068901854275193,\n",
       " 0.006829231358743792,\n",
       " 0.005551123902275826,\n",
       " 0.005031046540184927,\n",
       " 0.0032495040900099876,\n",
       " 0.005671524517806326,\n",
       " 0.004166638450693443,\n",
       " 0.002776480910590468,\n",
       " 0.005185325079111191,\n",
       " 0.0060983959742713385,\n",
       " 0.003201770936389387,\n",
       " 0.004667901791928189,\n",
       " 0.0033338186268573786,\n",
       " 0.004296626933970104,\n",
       " 0.00827161531068287,\n",
       " 0.0043172990433162405,\n",
       " 0.006137730576754745,\n",
       " 0.008363975014495269,\n",
       " 0.004561030563589023,\n",
       " 0.003654733351378812,\n",
       " 0.0027927300025715183,\n",
       " 0.006212679919368222,\n",
       " 0.002539799884038904,\n",
       " 0.0066442735373347245,\n",
       " 0.003906849984786776,\n",
       " 0.002553725810727839,\n",
       " 0.0035727174951503686,\n",
       " 0.003543647821120428,\n",
       " 0.006898815539912453,\n",
       " 0.004054139409988355,\n",
       " 0.0038087462716840247,\n",
       " 0.00629445455464341,\n",
       " 0.004240423428667053,\n",
       " 0.0030735683976852524,\n",
       " 0.003071782512433555,\n",
       " 0.003251143676560374,\n",
       " 0.005619816748346972,\n",
       " 0.007810559331732336,\n",
       " 0.005236536388157095,\n",
       " 0.010992183973510997,\n",
       " 0.005670698587067468,\n",
       " 0.0025479846333742047,\n",
       " 0.011746219623626762,\n",
       " 0.010957490523610827,\n",
       " 0.006747758426958911,\n",
       " 0.006539504061510887,\n",
       " 0.004414523070147249,\n",
       " 0.00848293510252637,\n",
       " 0.004164390091285253,\n",
       " 0.005304989059832604,\n",
       " 0.005501454426291618,\n",
       " 0.015048769506545125,\n",
       " 0.004356667676446409,\n",
       " 0.010368991069901294,\n",
       " 0.008113529373016069,\n",
       " 0.0068662406318293675,\n",
       " 0.00639406915462027,\n",
       " 0.003736362975563838,\n",
       " 0.005917643286013707,\n",
       " 0.009651208931513475,\n",
       " 0.0033472054494294206,\n",
       " 0.0036429985433096878,\n",
       " 0.0034172142554293977,\n",
       " 0.00783528139810579,\n",
       " 0.005871272996923734,\n",
       " 0.0022840598236180732,\n",
       " 0.004121633309922382,\n",
       " 0.007093655338024357,\n",
       " 0.0034580092382163526,\n",
       " 0.01323887668154952,\n",
       " 0.0022243808291224298,\n",
       " 0.0029925330053731693,\n",
       " 0.005092811193468684,\n",
       " 0.005361275558374297,\n",
       " 0.012703119384737999,\n",
       " 0.0018271457141111115,\n",
       " 0.00736320545329194,\n",
       " 0.005196989451919117,\n",
       " 0.004243284858941883,\n",
       " 0.003861753483301429,\n",
       " 0.0036003586652023434,\n",
       " 0.0025627704846461186,\n",
       " 0.0044329240556727515,\n",
       " 0.004911977935629557,\n",
       " 0.0057444896439155955,\n",
       " 0.0027248533268499115,\n",
       " 0.005758048377101789,\n",
       " 0.008394146842597889,\n",
       " 0.002782478094871934,\n",
       " 0.0061899093884253496,\n",
       " 0.004051399544781021,\n",
       " 0.006932714771774926,\n",
       " 0.0033696457566487975,\n",
       " 0.0046084374620931345,\n",
       " 0.0055643826601087425,\n",
       " 0.0067972523247473,\n",
       " 0.0030527933691337555,\n",
       " 0.00793667872662204,\n",
       " 0.002162895152931263,\n",
       " 0.0039979277374409625,\n",
       " 0.002989703551203934,\n",
       " 0.003875648202441182,\n",
       " 0.0060422672564592285,\n",
       " 0.01973731619000896,\n",
       " 0.002528139327100574,\n",
       " 0.004879125203677137,\n",
       " 0.005272600475315944,\n",
       " 0.0031155012084913866,\n",
       " 0.003973731598226803,\n",
       " 0.007384820783812536,\n",
       " 0.005925864137733722,\n",
       " 0.0031540254788525826,\n",
       " 0.0035263264881693975,\n",
       " 0.006596813542460699,\n",
       " 0.004534523076862167,\n",
       " 0.0022684964512284223,\n",
       " 0.003915189997692316,\n",
       " 0.008650738969407566,\n",
       " 0.003280447538623064,\n",
       " 0.0032668333580287514,\n",
       " 0.002712324497731601,\n",
       " 0.003285226336554944,\n",
       " 0.005152479886931866,\n",
       " 0.003428849387082454,\n",
       " 0.004354241446265568,\n",
       " 0.0018723131655316947,\n",
       " 0.004318321373821469,\n",
       " 0.002102202489254517,\n",
       " 0.0027869249855199674,\n",
       " 0.0015390282201840633,\n",
       " 0.005239019366671838,\n",
       " 0.008320658643095785,\n",
       " 0.007186240075736228,\n",
       " 0.005358206293120213,\n",
       " 0.007190810340915716,\n",
       " 0.005773723859293015,\n",
       " 0.004241637859430473,\n",
       " 0.006560186876054154,\n",
       " 0.0036415946165189025,\n",
       " 0.005260288105766523,\n",
       " 0.007852902986095896,\n",
       " 0.003072791264236341,\n",
       " 0.0020733219192770923,\n",
       " 0.0035341945508681805,\n",
       " 0.007808281964452362,\n",
       " 0.005117963816860487,\n",
       " 0.003423876440339689,\n",
       " 0.005185528387778244,\n",
       " 0.014068198504364086,\n",
       " 0.002144685989185238,\n",
       " 0.004582547741084909,\n",
       " 0.003413080286926739,\n",
       " 0.0043908695373666325,\n",
       " 0.005360502886581195,\n",
       " 0.003428036637880494,\n",
       " 0.0032742290536651292,\n",
       " 0.008311600121107106,\n",
       " 0.0029266213594064706,\n",
       " 0.006762572630290672,\n",
       " 0.008252708729185904,\n",
       " 0.0038338062076499423,\n",
       " 0.007758950079206543,\n",
       " 0.004454545354123921,\n",
       " 0.0057856345838291955,\n",
       " 0.002718133834311979,\n",
       " 0.0038174071041883174,\n",
       " 0.006713646183655075,\n",
       " 0.008194963900115874,\n",
       " 0.005209503833088775,\n",
       " 0.021758618733448674,\n",
       " 0.004825999054407285,\n",
       " 0.0036817126631900118,\n",
       " 0.0126521514188101,\n",
       " 0.007618979207075316,\n",
       " 0.003570692125751545,\n",
       " 0.0036766734084500573,\n",
       " 0.0038603125177487027,\n",
       " 0.013949166193346432,\n",
       " 0.0032396624146527274,\n",
       " 0.0034568531705185057,\n",
       " 0.006306033669159569,\n",
       " 0.004541812228148646,\n",
       " 0.004311129492678037,\n",
       " 0.004929539351895217,\n",
       " 0.0076581455887385404,\n",
       " 0.006780460717114587,\n",
       " 0.007830705849114473,\n",
       " 0.0077658029607934635,\n",
       " 0.00424676526151387,\n",
       " 0.0026290333431170988,\n",
       " 0.0014775522759595005,\n",
       " 0.005269663495161509,\n",
       " 0.005656043943287504,\n",
       " 0.00217764213028515,\n",
       " 0.0038999782535694637,\n",
       " 0.009462383200197398,\n",
       " 0.005630729054655122,\n",
       " 0.0046918047149276075,\n",
       " 0.006513856582787487,\n",
       " 0.006845153340086985,\n",
       " 0.00620510330071867,\n",
       " 0.009277775484278343,\n",
       " 0.00636172907485211,\n",
       " 0.0033118988058766933,\n",
       " 0.006232451962353605,\n",
       " 0.004590840922514575,\n",
       " 0.006265604602932909,\n",
       " 0.003609545486578495,\n",
       " 0.00281155684825885,\n",
       " 0.0032503277788645704,\n",
       " 0.004237062700566436,\n",
       " 0.007538888747203858,\n",
       " 0.006280848741619938,\n",
       " 0.003628373770501642,\n",
       " 0.0035313465401639317,\n",
       " 0.0029911777381432564,\n",
       " 0.006752330575558699,\n",
       " 0.0036486082836892034,\n",
       " 0.004976733955239577,\n",
       " 0.008393482834301878,\n",
       " 0.005175212646086511,\n",
       " 0.00588451872376805,\n",
       " 0.005518062673425464,\n",
       " 0.0036600273869132503,\n",
       " 0.0036617343480032445,\n",
       " 0.0015483716712517478,\n",
       " 0.00551645646536362,\n",
       " 0.002492254767355423,\n",
       " 0.005212241060118999,\n",
       " 0.00734164630145315,\n",
       " 0.0034627785723368295,\n",
       " 0.003845571045027755,\n",
       " 0.00791402215924799,\n",
       " 0.007131138334033274,\n",
       " 0.006535585410546281,\n",
       " 0.004049834381236362,\n",
       " 0.007887092607195962,\n",
       " 0.0022970391321523766,\n",
       " 0.005695572319180465,\n",
       " 0.0017097884283463454,\n",
       " 0.005814872786529608,\n",
       " 0.003433486516820513,\n",
       " 0.004051932877826556,\n",
       " 0.0022779471485367977,\n",
       " 0.003578566864875542,\n",
       " 0.005829246810896119,\n",
       " 0.00939991509304746,\n",
       " 0.0057195580435036265,\n",
       " 0.006829757642430722,\n",
       " 0.011734098718298938,\n",
       " 0.0060674725816029515,\n",
       " 0.005029439237964011,\n",
       " 0.0036425714373394167,\n",
       " 0.0047152823974615605,\n",
       " 0.004498647218238841,\n",
       " 0.00517744531970934,\n",
       " 0.002305172111958076,\n",
       " 0.006887417760272847,\n",
       " 0.008666588305501807,\n",
       " 0.003410394416353059,\n",
       " 0.010175224493710234,\n",
       " 0.0032417947138874284,\n",
       " 0.006768746998009675,\n",
       " 0.004121216326505793,\n",
       " 0.0018719688894971221,\n",
       " 0.0052429757249588685,\n",
       " 0.004088682073356998,\n",
       " 0.004405756611450188,\n",
       " 0.0416372371440535,\n",
       " 0.01005550221421552,\n",
       " 0.007052906172136242,\n",
       " 0.0040704666177246475,\n",
       " 0.00545797515047899,\n",
       " 0.006846017881547731,\n",
       " 0.003689197884913168,\n",
       " 0.003486683697118888,\n",
       " 0.0023130018995456683,\n",
       " 0.0029007968148937694,\n",
       " 0.005116607204287486,\n",
       " 0.007139549584027938,\n",
       " 0.003272220144214318,\n",
       " 0.008023085992548409,\n",
       " 0.026917311611987963,\n",
       " 0.008956910517031553,\n",
       " 0.002943382733884941,\n",
       " 0.03478210329600685,\n",
       " 0.006459194439955663,\n",
       " 0.006124353233122555,\n",
       " 0.0064005264698746185,\n",
       " 0.007269930292736922,\n",
       " 0.003302503550591516,\n",
       " 0.002498872203260996,\n",
       " 0.011663884769619305,\n",
       " 0.0044381105828093705,\n",
       " 0.0036967839370810403,\n",
       " 0.006188522263941966,\n",
       " 0.0035469440458236823,\n",
       " 0.004874360617187585,\n",
       " 0.005580249540306702,\n",
       " 0.007496847391743196,\n",
       " 0.00508500691115072,\n",
       " 0.0033337862516747384,\n",
       " 0.004586596549099639,\n",
       " 0.0032793955231449528,\n",
       " 0.006653674893470404,\n",
       " 0.00640344059567963,\n",
       " 0.00319155597833111,\n",
       " 0.0032153265008439996,\n",
       " 0.004461891735715883,\n",
       " 0.0053585795879657625,\n",
       " 0.007423472373558557,\n",
       " 0.003992454003831602,\n",
       " 0.0030225545876995568,\n",
       " 0.004661099003077073,\n",
       " 0.004183700127717939,\n",
       " 0.0022753674470979758,\n",
       " 0.005424028256609273,\n",
       " 0.005362096155827825,\n",
       " 0.004862092139914223,\n",
       " 0.0035683555912658605,\n",
       " 0.0031176036573538585,\n",
       " 0.004883414748646748,\n",
       " 0.01170931935908265,\n",
       " 0.007533495678921358,\n",
       " 0.004046192811543773,\n",
       " 0.0028980308423314036,\n",
       " 0.0038477021952317034,\n",
       " 0.0028758555561634,\n",
       " 0.004153358759119917,\n",
       " 0.004396824619948696,\n",
       " 0.002259267255217615,\n",
       " 0.0037483439864336985,\n",
       " 0.0070856829043333906,\n",
       " 0.006746601715087224,\n",
       " 0.0037514568261241554,\n",
       " 0.006119895095654305,\n",
       " 0.0032963261326938945,\n",
       " 0.012163661256125297,\n",
       " 0.005443805444365094,\n",
       " 0.005488747986875128,\n",
       " 0.0029273774786739877,\n",
       " 0.008925761173460845,\n",
       " 0.0024213236270278615,\n",
       " 0.003930955046409808,\n",
       " 0.0018280061850272466,\n",
       " 0.007559243714300072,\n",
       " 0.006186703543736559,\n",
       " 0.0035470193580538286,\n",
       " 0.00463853693520893,\n",
       " 0.003138365860146394,\n",
       " 0.00755508956157344,\n",
       " 0.005055664766374926,\n",
       " 0.003769727824159436,\n",
       " 0.0032007840134223313,\n",
       " 0.012459802560139845,\n",
       " 0.00661315750636728,\n",
       " 0.005421867923034232,\n",
       " 0.0027788550376704546,\n",
       " 0.007330221698801924,\n",
       " 0.0069952434857707526,\n",
       " 0.002165771708605465,\n",
       " 0.0030154116261570775,\n",
       " 0.0019531149138719774,\n",
       " 0.0027214486512691684,\n",
       " 0.003987048858387099,\n",
       " 0.0027103814381870396,\n",
       " 0.003308758754243525,\n",
       " 0.0071948207256397985,\n",
       " 0.006777500727579842,\n",
       " 0.005726241836817639,\n",
       " 0.012740176190441911,\n",
       " 0.0033515852226246447,\n",
       " 0.007583597227764812,\n",
       " 0.004104612223073493,\n",
       " 0.003599722843322096,\n",
       " 0.003665804035103511,\n",
       " 0.004203979558367351,\n",
       " 0.004625519156068046,\n",
       " 0.008421646626542389,\n",
       " 0.0036790611320344562,\n",
       " 0.008219353338096796,\n",
       " 0.0025619133769117066,\n",
       " 0.007308273922094199,\n",
       " 0.010569806376399673,\n",
       " 0.0076377508636254095,\n",
       " 0.007093368089372331,\n",
       " 0.009942399210672817,\n",
       " 0.010808108405210138,\n",
       " 0.003169103726818997,\n",
       " 0.014187332356397896,\n",
       " 0.011340029283986029,\n",
       " 0.003888667851683159,\n",
       " 0.006150407408829177,\n",
       " 0.0028332986310402176,\n",
       " 0.008686516468283993,\n",
       " 0.0058017231437081,\n",
       " 0.004752078219658725,\n",
       " 0.007562223005969076,\n",
       " 0.0091548683723742,\n",
       " 0.013755105085026961,\n",
       " 0.008575364781418716,\n",
       " 0.007236557346153895,\n",
       " 0.0036753838914888887,\n",
       " 0.007813315056623821,\n",
       " 0.0031540772578738,\n",
       " 0.004128527928882256,\n",
       " 0.006160343457896108,\n",
       " 0.0015387027611531452,\n",
       " 0.00648634577800047,\n",
       " 0.004849731656773636,\n",
       " 0.0030125886870455685,\n",
       " 0.005791448597486838,\n",
       " 0.00832592196406041,\n",
       " 0.0033049164175825664,\n",
       " 0.0029153160275161615,\n",
       " 0.007969062732836018,\n",
       " 0.002926493478888589,\n",
       " 0.009174728516470802,\n",
       " 0.0026654960666643666,\n",
       " 0.004238115166407561,\n",
       " 0.005704752569598382,\n",
       " 0.004289760179712175,\n",
       " 0.0020644692386750704,\n",
       " 0.002984231921367331,\n",
       " 0.0036671793056558323,\n",
       " 0.004845792657607992,\n",
       " 0.007464595980457775,\n",
       " 0.004411953130076832,\n",
       " 0.0043118396149370315,\n",
       " 0.00868814829691712,\n",
       " 0.004676252775681456,\n",
       " 0.007624047945886717,\n",
       " 0.0042719144249321475,\n",
       " 0.005775388871109673,\n",
       " 0.003345607869071419,\n",
       " 0.004330498779249141,\n",
       " 0.004241549461093698,\n",
       " 0.00530634066166128,\n",
       " 0.009642965965242792,\n",
       " 0.004674430888714685,\n",
       " 0.014155526488058004,\n",
       " 0.005370291130348377,\n",
       " 0.0019637192330059115,\n",
       " 0.002717225744811604,\n",
       " 0.005566143375204695,\n",
       " 0.005679602785514642,\n",
       " 0.004540876474079168,\n",
       " 0.003125226654262485,\n",
       " 0.0022022485351341535,\n",
       " 0.002340126954039546,\n",
       " 0.0077390344774205325,\n",
       " 0.003188030140929562,\n",
       " 0.004513029872757954,\n",
       " 0.005048226361930229,\n",
       " 0.004827043788787517,\n",
       " 0.004927588377303926,\n",
       " 0.0062429183189315575,\n",
       " 0.004346254997949827,\n",
       " 0.005260068671013451,\n",
       " 0.0070223246078967485,\n",
       " 0.004300643249435544,\n",
       " 0.0022780306505993586,\n",
       " 0.0023248030473144105,\n",
       " 0.0027165181446107004,\n",
       " 0.005110892559529042,\n",
       " 0.002556014389787275,\n",
       " 0.00934481496309332,\n",
       " 0.004701507408969955,\n",
       " 0.0043385920134513195,\n",
       " 0.009244998270360067,\n",
       " 0.005819572731099613,\n",
       " 0.005975600344545377,\n",
       " 0.012351109660979473,\n",
       " 0.005884756924109612,\n",
       " 0.004608244629872376,\n",
       " 0.005911320913802443,\n",
       " 0.007801392559118043,\n",
       " 0.006464774989575146,\n",
       " 0.003488441808501519,\n",
       " 0.010037734231645615,\n",
       " 0.004518813474336939,\n",
       " 0.004594803063729507,\n",
       " 0.005368443583926282,\n",
       " 0.006454552821598372,\n",
       " 0.004936810308498687,\n",
       " 0.010331332141654447,\n",
       " 0.006824737676648614,\n",
       " 0.0064042442506358705,\n",
       " 0.004062883409426705,\n",
       " 0.0073969088372767755,\n",
       " 0.0047687954982122815,\n",
       " 0.005155391379310122,\n",
       " 0.0047175690136377945,\n",
       " 0.004688604354947464,\n",
       " 0.004102279025474985,\n",
       " 0.003857274171064447,\n",
       " 0.0020706431595520383,\n",
       " 0.004174206777927695,\n",
       " 0.00827373036913556,\n",
       " 0.0026408270520290105,\n",
       " 0.010862250858483552,\n",
       " 0.002219611335624659,\n",
       " 0.0028329061842086185,\n",
       " 0.0024929590556520263,\n",
       " 0.0030043128440065564,\n",
       " 0.006078139619107812,\n",
       " 0.008917980372022336,\n",
       " 0.010358075408082807,\n",
       " 0.004244209805587441,\n",
       " 0.0033974345004491903,\n",
       " 0.005971661613858382,\n",
       " 0.005123606344161409,\n",
       " 0.010863218667480079,\n",
       " 0.011880121587979813,\n",
       " 0.0029760312037232428,\n",
       " 0.0032695133351009595,\n",
       " 0.004122851842516286,\n",
       " 0.003412428368503901,\n",
       " 0.010095889798468613,\n",
       " 0.004573982688884167,\n",
       " 0.008026901514114705,\n",
       " 0.004283564474228338,\n",
       " 0.0038929491653292405,\n",
       " 0.014867087289504798,\n",
       " 0.015278098252532521,\n",
       " 0.006630162826399773,\n",
       " 0.013948572745072801,\n",
       " 0.005974258056022389,\n",
       " 0.005882874207732716,\n",
       " 0.0049208756505579685,\n",
       " 0.003547450759762845,\n",
       " 0.004913007108136735,\n",
       " 0.006300468932947282,\n",
       " 0.002830775487414877,\n",
       " 0.003608232089814913,\n",
       " 0.005902684559173929,\n",
       " 0.005408518902710487,\n",
       " 0.004979306736851479,\n",
       " 0.005558298232355614,\n",
       " 0.00258209685024147,\n",
       " 0.0031711178421713324,\n",
       " 0.002150072721386827,\n",
       " 0.00216225313049099,\n",
       " 0.0034687417164758648,\n",
       " 0.006709835444355279,\n",
       " 0.002452365443917658,\n",
       " 0.0040842946859072455,\n",
       " 0.007983355587096575,\n",
       " 0.003609236796432012,\n",
       " 0.0035599165150796675,\n",
       " 0.0030658393752511534,\n",
       " 0.003967160945086486,\n",
       " 0.0025890014367630724,\n",
       " 0.0033798461715851677,\n",
       " 0.00512280576870301,\n",
       " 0.01060739286882198,\n",
       " 0.003003032667266198,\n",
       " 0.022551443538760197,\n",
       " 0.004820480380449613,\n",
       " 0.0032257158298603277,\n",
       " 0.006309812037481802,\n",
       " 0.004220376606004438,\n",
       " 0.011049188413332498,\n",
       " 0.006000865223458685,\n",
       " 0.006032704622669513,\n",
       " 0.002962851886992725,\n",
       " 0.0024776152471341012,\n",
       " 0.0059455403932904905,\n",
       " 0.0040279849736691515,\n",
       " 0.0042712255519079655,\n",
       " 0.005158265413041607,\n",
       " 0.0055118962843934294,\n",
       " 0.0038492663377547717,\n",
       " 0.0056388601536861635,\n",
       " 0.004527538098437332,\n",
       " 0.005155160993309104,\n",
       " 0.004510575841354459,\n",
       " 0.0029679166658222794,\n",
       " 0.0055820733204608826,\n",
       " 0.002819264046872424,\n",
       " 0.010610888302636939,\n",
       " 0.0065321605262469735,\n",
       " 0.00418425030891219,\n",
       " 0.003935303204422345,\n",
       " 0.008487947298928105,\n",
       " 0.00416188259348285,\n",
       " 0.004603213151382811,\n",
       " 0.0042876011511727525,\n",
       " 0.005738059396166435,\n",
       " 0.007790208600513031,\n",
       " 0.0050066112029220795,\n",
       " 0.0031494002460209676,\n",
       " 0.005419613176186798,\n",
       " 0.008434848203137014,\n",
       " 0.005636568655461685,\n",
       " 0.005142114985281292,\n",
       " 0.010669099152563574,\n",
       " 0.0028396413898548667,\n",
       " 0.005553595668355197,\n",
       " 0.004057151667254428,\n",
       " 0.0021011901322015103,\n",
       " 0.009159264396207496,\n",
       " 0.00960409520760561,\n",
       " 0.004794489604693802,\n",
       " 0.006240010346026315,\n",
       " 0.0023477629846409315,\n",
       " 0.017939111638892766,\n",
       " 0.00508777451057085,\n",
       " 0.0030617451147325206,\n",
       " 0.0035259714095547106,\n",
       " 0.005642515863237607,\n",
       " 0.007056304119131644,\n",
       " 0.004009881593242703,\n",
       " 0.003445735334449581,\n",
       " 0.006649039813084239,\n",
       " 0.003785529589795206,\n",
       " 0.0034316351375674697,\n",
       " 0.005038438919310747,\n",
       " 0.002775612876898565,\n",
       " 0.006444500254330074,\n",
       " 0.003997935539416016,\n",
       " 0.0028508112304859614,\n",
       " 0.010750533640817513,\n",
       " 0.004143612902065705,\n",
       " 0.01175434425729666,\n",
       " 0.005270543016924834,\n",
       " 0.005110643307849239,\n",
       " 0.0033333382053474473,\n",
       " 0.004271543201438218,\n",
       " 0.003959086391655126,\n",
       " 0.0029543965787212187,\n",
       " 0.004838322370595671,\n",
       " 0.004335254005169773,\n",
       " 0.0057486361310523214,\n",
       " 0.008925880888110757,\n",
       " 0.003080705320337021,\n",
       " 0.0032538001488665444,\n",
       " 0.008667355295677984,\n",
       " 0.0023766683567694037,\n",
       " 0.0034340755213336798,\n",
       " 0.00529628769632774,\n",
       " 0.005543923183098197,\n",
       " 0.002573571829656504,\n",
       " 0.0048056746835868636,\n",
       " 0.002362138423138014,\n",
       " 0.006800787721695883,\n",
       " 0.005891594946612137,\n",
       " 0.0071851540874204685,\n",
       " 0.005651885929832012,\n",
       " 0.0018916431498964905,\n",
       " 0.004097108166872572,\n",
       " 0.007226636402336623,\n",
       " 0.0027190769506677003,\n",
       " 0.007487519706909837,\n",
       " 0.010361065816745268,\n",
       " 0.008849407431465154,\n",
       " 0.003973858554843086,\n",
       " 0.009949310448183042,\n",
       " 0.008771307296583965,\n",
       " 0.004796300655805512,\n",
       " 0.0039562988254053496,\n",
       " 0.004738712937730978,\n",
       " 0.004149323493825346,\n",
       " 0.005325226159655372,\n",
       " 0.005465886732839452,\n",
       " 0.0038165811276072007,\n",
       " 0.0060764050252641744,\n",
       " 0.004062314138292821,\n",
       " 0.007759288470421554,\n",
       " 0.003955681072769083,\n",
       " 0.00322095532304677,\n",
       " 0.0018301513441492906,\n",
       " 0.00964952600654442,\n",
       " 0.005800113763107798,\n",
       " 0.004245571608146812,\n",
       " 0.007879838328933981,\n",
       " 0.0026980035486407266,\n",
       " 0.005271703130897425,\n",
       " 0.0027707313985716442,\n",
       " 0.003683075247261193,\n",
       " 0.002409709085610758,\n",
       " 0.006127214417510935,\n",
       " 0.02073504222015334,\n",
       " 0.0056011008563575885,\n",
       " 0.004270852996993369,\n",
       " 0.003993197970261413,\n",
       " 0.007995960794069347,\n",
       " 0.006034831327899697,\n",
       " 0.003440686652498463,\n",
       " 0.0055185557990440415,\n",
       " 0.006554548686245116,\n",
       " 0.006015398602736145,\n",
       " 0.002681955738816048,\n",
       " 0.0020980117534962913,\n",
       " 0.005761702086450433,\n",
       " 0.0030286490488127746,\n",
       " 0.008845260120863013,\n",
       " 0.00498508499126163,\n",
       " 0.004687898559664091,\n",
       " 0.007395309228407064,\n",
       " 0.006897181413555188,\n",
       " 0.003058967218856259,\n",
       " 0.007138394245788808,\n",
       " 0.00591871738026338,\n",
       " 0.002133838511004387,\n",
       " 0.0022802739497750062,\n",
       " 0.005309723962763957,\n",
       " 0.006341022847732299,\n",
       " 0.0022665326371773104,\n",
       " 0.0055636319004274655,\n",
       " 0.003456818043633355,\n",
       " 0.003932472231146014,\n",
       " 0.0024144409520988563,\n",
       " 0.004031970741725869,\n",
       " 0.0066546295225321786,\n",
       " 0.02868990571719182,\n",
       " ...]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data = np.vstack([valideImages , anomalyImages])\n",
    "np.random.shuffle(testing_data)\n",
    "testing_data = testing_data.astype(\"float64\") / 255.0\n",
    "outputs = autoencoder.predict(testing_data)\n",
    "\n",
    "errors = []\n",
    "for (image, recon) in zip(testing_data, outputs):\n",
    "    mse = np.mean((image - recon) ** 2)\n",
    "    errors.append(mse)\n",
    "    \n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029523429"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalyData = anomalyImages.astype(\"float32\") / 255.0\n",
    "anomalyOutputs = autoencoder.predict(anomalyData)\n",
    "\n",
    "anomalyErrors = []\n",
    "for (image, recon) in zip(anomalyData, anomalyOutputs):\n",
    "    mse = np.mean((image - recon) ** 2)\n",
    "    anomalyErrors.append(mse)\n",
    "    \n",
    "np.mean(anomalyErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0054253023"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valideData = valideImages.astype(\"float32\") / 255.0\n",
    "valideOutputs = autoencoder.predict(valideData)\n",
    "\n",
    "valideErrors = []\n",
    "for (image, recon) in zip(valideData, valideOutputs):\n",
    "    mse = np.mean((image - recon) ** 2)\n",
    "    valideErrors.append(mse)\n",
    "    \n",
    "np.mean(valideErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008904977\n",
      "0.06308336\n",
      "0.029523429\n",
      "0.0011431094\n",
      "0.046525937\n",
      "0.0054253023\n"
     ]
    }
   ],
   "source": [
    "print(np.min(anomalyErrors))\n",
    "print(np.max(anomalyErrors))\n",
    "print(np.mean(anomalyErrors))\n",
    "print(np.min(valideErrors))\n",
    "print(np.max(valideErrors))\n",
    "print(np.mean(valideErrors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  82,   93,  155,  173,  178,  215,  244,  335,  387,  453,  552,\n",
       "        566,  569,  808,  841,  890,  966,  999, 1175, 1178, 1243, 1250,\n",
       "       1255, 1299, 1375, 1389, 1438, 1453, 1473, 1475, 1488, 1491, 1542,\n",
       "       1574, 1602, 1630, 1669, 1721, 1785, 1832, 1851, 1897, 1945, 1986,\n",
       "       2045, 2051, 2079, 2135, 2216, 2286, 2337, 2411, 2422, 2425, 2471,\n",
       "       2487, 2500, 2553, 2565, 2604, 2635, 2649, 2670, 2742, 2761, 2778,\n",
       "       2801, 2851, 2879, 2899, 2961, 2965, 2980, 3021, 3054, 3108, 3163,\n",
       "       3272, 3273, 3280, 3287, 3447, 3454, 3552, 3587, 3642, 3651, 3682,\n",
       "       3746, 3751, 3814, 3881, 3985, 4073, 4095, 4096, 4144, 4186, 4215,\n",
       "       4247, 4249, 4254, 4357, 4381, 4432, 4435, 4442, 4463, 4464, 4552,\n",
       "       4589, 4625, 4626, 4636, 4722, 4728, 4795, 4891, 4937, 4979, 5095,\n",
       "       5274, 5286, 5422, 5438, 5445], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#thresh = np.quantile(errors, 0.99)\n",
    "thresh = np.float64(0.015)\n",
    "outliers = np.where(errors >= thresh)[0]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABB0lEQVR4nGNgGDAgs/X/HQEccrav/v79u0sWu+THv3///v17VRpNmIWBgYGB4TcDA8ODr6//YtVZ8PfvXUFc7hG9+/cKMwM7t8fjx48fdwuwoMru+Ps3NP7mXygo4kSXfP39LxzUQUQZIVR9DROE8WXaQ1b5nL+ux5C1Nv79+/fv318bRBgYGBjsH21D9dKNv3/f1BpBeXXfk1FkZWpqzOCc+L970VyMDDb+3cLAwMCEXZKVwROXPuGFf/9+QhWana3NwMDAwCDl++Tv378TUSUf/31/JmPP5cuP//79+/dvGqok30dEEP3cjx4PRW9hcoeLGBgY4MEHAbLZkBDfvv8nLrfSHAAA2XCFTYIX/MkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x202BEF9BBA8>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.squeeze((testing_data[3054] * 255).astype(\"uint8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032640347804641104"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = autoencoder.predict(np.expand_dims(testing_data[3054], axis=0))\n",
    "mse = np.mean((testing_data[3054] - img) ** 2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888817"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = trainX[500]\n",
    "decoded = autoencoder.predict(np.expand_dims(x_train[500], axis=0))\n",
    "mse = np.mean((img - decoded) ** 2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
